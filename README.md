# Context Engine Inteligente para Marketplace (Mercado Libre)

Prototipo de un **Context Engine** que unifica el contexto de Ã­tems de un marketplace (Ã­tem + vendedor + seÃ±ales de â€œsaludâ€ del Ã­tem) para que un agente/LLM pueda tomar mejores decisiones.

Este proyecto implementa:
1) **Entidad 360 / Feature Engineering** (perfil denso del Ã­tem)
2) **Retrieval inteligente** (bÃºsqueda semÃ¡ntica + filtro duro de precio)
3) **Insights en tiempo real con GenAI** (LLM genera un JSON estable)

---

## âœ… QuÃ© entrega este repo (Bloques del Challenge)

### Bloque 1 â€” Modelado Entidad 360 (Feature Engineering)
Se transforma el dataset crudo a un perfil mÃ¡s â€œdensoâ€ y se calculan mÃ©tricas de salud del Ã­tem, por ejemplo:
- **stock_ratio**
- **sell_through**
- **seÃ±ales de tags** (normalizaciÃ³n/cantidad), y otras features ligeras

ğŸ“Œ Implementado en: `src/features.py` (y usado desde el notebook)

### Bloque 2 â€” Intelligent Retrieval (Embeddings + filtros)
Dada una bÃºsqueda del usuario (ej: *â€œBusco una laptop para ediciÃ³n de video que sea econÃ³micaâ€*), el sistema recupera items combinando:
- **Filtro duro**: `max_price`
- **Filtro blando**: similitud semÃ¡ntica por embeddings (`score`)

Se guardan artifacts en `.pkl` para reusar sin recalcular.

ğŸ“Œ Implementado en: `notebooks/01_generate_data.ipynb`  
ğŸ“Œ Artifacts: `artifacts/retrieval_artifacts.pkl`, `artifacts/retrieval_artifacts_laptops.pkl` *(generados localmente)*

### Bloque 3 â€” Real-time Insights & Summarization (GenAI)
Con el contexto recuperado, un LLM (OpenAI) genera una **ficha comparativa** en **JSON estable**:
- `comparative_summary`
- `top_recommendation` (+ reason)
- `risk_alerts`
- `market_insight`

ğŸ“Œ Implementado en: `notebooks/01_generate_data.ipynb`  
ğŸ“Œ Output ejemplo: `notebooks/insights_block3.json`

### Bloque 4 â€” Arquitectura (MCP & Escalabilidad) *(pendiente / opcional)*
Diagrama y diseÃ±o de integraciÃ³n con un servidor MCP y estrategia para mantener reputaciÃ³n del vendedor actualizada sin re-indexar todo.

<img width="1178" height="432" alt="image" src="https://github.com/user-attachments/assets/cbca8233-6eed-44f2-9b4f-54d64c7c03d6" />

Pregunta: Â¿CÃ³mo asegurarÃ­as que los datos del vendedor estÃ©n actualizados sin re-indexar?

Respuesta: UtilizarÃ­a una estrategia de consulta hÃ­brida en el servidor MCP. Mantengo el Ã­ndice de vectores para la bÃºsqueda semÃ¡ntica (que es estÃ¡tica), pero creo una 'Tool' especÃ­fica que consulta directamente el dataset de vendedores o una API en el momento en que el agente lo solicita. AsÃ­, el agente recibe la reputaciÃ³n 'en vivo' recuperada por ID, sin necesidad de generar nuevos embeddings para todo el dataset.

---

## Estructura del repositorio

context-engine-crewai/
â”œâ”€ artifacts/ # artifacts generados (pkl/parquet)
â”œâ”€ data/ # datos
â”œâ”€ notebooks/
â”‚ â”œâ”€ 01_generate_data.ipynb # pipeline principal Bloques 1â€“3
â”‚ â”œâ”€ 02_demo_crewai.ipynb 
â”‚ â””â”€ insights_block3.json # salida JSON del Bloque 3
â”œâ”€ src/
â”‚ â””â”€ features.py # feature engineering + helpers
â”œâ”€ requirements.txt
â”œâ”€ .env.example
â””â”€ README.md
